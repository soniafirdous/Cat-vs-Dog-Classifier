# ğŸ±ğŸ¶ Cat vs Dog Image Classification using CNN & TensorFlow

## ğŸ“Œ Project Overview
This project builds a **binary image classification system (Cat vs Dog)** using **TensorFlow and CNNs**. The complete deep learning pipeline is implemented using **tf.data.Dataset** for efficient data handling and **regularization techniques** to reduce overfitting.

---

## ğŸ“‚ Dataset
- **Dataset:** Cats vs Dogs
- **Source:** Kaggle
- **Classes:** Cat, Dog
- **Image Size:** 224 Ã— 224 Ã— 3

---

## ğŸ”„ Project Workflow

### 1ï¸âƒ£ Download Dataset
- Dataset downloaded from **Kaggle**
- Extracted into training and validation directories

---

### 2ï¸âƒ£ Import Libraries
Key libraries used:
- TensorFlow / Keras
- NumPy
- Matplotlib

---

### 3ï¸âƒ£ Load Images using `tf.data.Dataset`
- Images loaded efficiently using TensorFlowâ€™s data pipeline
- Enables fast and scalable training

---

### 4ï¸âƒ£ Create Data Augmentation Layers
Applied to training data to improve generalization:
- Random Flip
- Random Rotation
- Random Zoom

---

### 5ï¸âƒ£ Create Preprocessing Functions
- Resize images to 224 Ã— 224
- Normalize pixel values
- Apply augmentation only on training data

---

### 6ï¸âƒ£ Data Pipeline Optimization
Applied in sequence:
```text
map â†’ shuffle â†’ prefetch
Improves training speed

Prevents I/O bottlenecks

7ï¸âƒ£ Build CNN Model (Anti-Overfitting)

Model includes:

Convolutional layers

Batch Normalization

Dropout layers

Global Average Pooling (instead of Flatten)

8ï¸âƒ£ Compile the Model

Optimizer: Adam

Loss Function: Binary Crossentropy

Metrics: Accuracy

9ï¸âƒ£ Add Early Stopping

Monitors validation loss

Stops training when performance stops improving

Prevents overfitting

ğŸ”Ÿ Train the Model

Model trained on augmented data

Validation performed on unseen images

ğŸ—ï¸ Model Architecture
Input Image
â†“
Conv2D + BatchNorm + ReLU
â†“
MaxPooling
â†“
Conv2D + BatchNorm + ReLU
â†“
Global Average Pooling
â†“
Dropout
â†“
Dense (Sigmoid)

ğŸ“Š Evaluation Metrics

Accuracy

Training vs Validation Loss

Overfitting Analysis

ğŸš€ Key Learnings

tf.data.Dataset improves performance and scalability

Data augmentation reduces overfitting

EarlyStopping prevents unnecessary training

Global Average Pooling reduces parameters

ğŸ› ï¸ Tech Stack

Python | TensorFlow | Keras | CNN | tf.data | Deep Learning

ğŸ‘©â€ğŸ’» Author

Sonia Firdous
Data Science & Deep Learning
